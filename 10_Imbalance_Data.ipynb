{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10.Imbalance_Data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPooctGRdo//C8Mt1p2nPbr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sureshmecad/Google-Colab/blob/master/10_Imbalance_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxT29-fFUMt8"
      },
      "source": [
        "https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb\r\n",
        "\r\n",
        "https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28\r\n",
        "\r\n",
        "https://www.kdnuggets.com/2020/01/5-most-useful-techniques-handle-imbalanced-datasets.html\r\n",
        "\r\n",
        "https://datascience.foundation/sciencewhitepaper/understanding-imbalanced-datasets-and-techniques-for-handling-them\r\n",
        "\r\n",
        "https://www.analyticsvidhya.com/blog/2017/03/imbalanced-data-classification/\r\n",
        "\r\n",
        "https://www.jeremyjordan.me/imbalanced-data/\r\n",
        "\r\n",
        "https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\r\n",
        "\r\n",
        "https://www.experfy.com/blog/ai-ml/imbalanced-datasets-guide-classification/\r\n",
        "\r\n",
        "https://medium.com/@itbodhi/handling-imbalanced-data-sets-in-machine-learning-5e5f33c70163\r\n",
        "\r\n",
        "https://www.topcoder.com/thrive/articles/How%20to%20Handle%20Imbalanced%20Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4DEjWTlUPd7"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2ItASvPnpFP"
      },
      "source": [
        "- **Binary Classification Problem:** A classification predictive modeling problem where all examples belong to **one of two classes.**\r\n",
        "\r\n",
        "- **Multiclass Classification Problem:** A classification predictive modeling problem where all examples belong to **one of three classes.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLS4wdj-nur1"
      },
      "source": [
        "- Many real-world classification problems have an **imbalanced class distribution**, such as \r\n",
        "  \r\n",
        "  1. Fraud detection\r\n",
        "\r\n",
        "  2. spam detection\r\n",
        "\r\n",
        "  3. Churn prediction\r\n",
        "\r\n",
        "  4. Claim Prediction\r\n",
        "\r\n",
        "  5. Default Prediction\r\n",
        "\r\n",
        "  6. Anomaly Detection\r\n",
        "\r\n",
        "  7. Outlier Detection\r\n",
        "\r\n",
        "  8. Intrusion Detection\r\n",
        "\r\n",
        "  9. Conversion Prediction.\r\n",
        "\r\n",
        "- **Ad Serving:** Click prediction datasets also don’t have a high clickthrough rate.\r\n",
        "\r\n",
        "- **Content moderation:** Does a post contain NSFW content?\r\n",
        "\r\n",
        "\r\n",
        "This problem is predominant in scenarios where anomaly detection is crucial like\r\n",
        "\r\n",
        "- Identification of rare diseases like cancer; tumours etc,\r\n",
        "\r\n",
        "- Electricity theft & pilferage\r\n",
        "\r\n",
        "- Fraudulent transactions in banks\r\n",
        "\r\n",
        "- Identify customer churn rate ( that is, what fraction of customers continue using a service)\r\n",
        "\r\n",
        "- Natural Disasters like Earthquakes\r\n",
        "Spam emails, etc.\r\n",
        "\r\n",
        "- An e-commerce company predicting which users will buy items on their platform\r\n",
        "\r\n",
        "- A manufacturing company analyzing produced materials for defects\r\n",
        "\r\n",
        "- Number of clients who closed a specific account in a bank or financial organization\r\n",
        "\r\n",
        "- Prediction of telecommunications equipment failures\r\n",
        "\r\n",
        "- Hardware fault detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3uUE-USjNH8"
      },
      "source": [
        "- So we define an **imbalanced dataset** as a dataset where the majority class is much larger than the minority class. There is no limit to how big the majority class has to be. Even when the **majority class is twice the size of the minority class**, it is still an imbalanced dataset.\r\n",
        "\r\n",
        "- Standard classifier algorithms like **Decision Tree and Logistic Regression** have a **bias** towards classes which have number of instances. They tend to **only predict the majority class data.** The features of the **minority class are treated as noise** and are often ignored. Thus, there is a high probability of the misclassification of the minority class as compared to the majority class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBmG-97ejIyB"
      },
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ7fIS0mTdGS"
      },
      "source": [
        "### What Is Data Imbalance?\r\n",
        "\r\n",
        "### 1. Finance\r\n",
        "\r\n",
        "- **Fraud detection datasets commonly have a fraud rate of ~1–2%**\r\n",
        "\r\n",
        "- Data imbalance usually reflects an unequal distribution of classes within a dataset. For example, in a **credit card fraud detection** dataset, most of the credit card transactions are **not fraud** and a **very few classes are fraud transactions.** This leaves us with something like 50:1 ratio between the fraud and non-fraud classes. \r\n",
        "\r\n",
        "### 2. Transportation/Airline\r\n",
        "\r\n",
        "- **Will Airplane failure occur?**\r\n",
        "\r\n",
        "- Suppose that you are working in a given company and you are asked to create a model that, based on various measurements at your disposal, predicts whether a product is **defective or not.** You decide to use your favourite classifier, train it on the data and voila : you get a 96.2% accuracy !\r\n",
        "Your boss is astonished and decides to use your model without any further tests. A few weeks later he enters your office and underlines the uselessness of your model. Indeed, the model you created has not found any defective product from the time it has been used in production.\r\n",
        "After some investigations, you find out that there is only around 3.8% of the product made by your company that are defective and your model just always answers “not defective”, leading to a 96.2% accuracy. The kind of “naive” results you obtained is due to the imbalanced dataset you are working with. The goal of this article is to review the different methods that can be used to tackle classification problems with imbalanced classes.\r\n",
        "\r\n",
        "- In such cases, you get a **pretty high accuracy** just by **predicting the majority class, but you fail to capture the minority class,** which is most often the point of creating the model in the first place.\r\n",
        "\r\n",
        "### 3. Healthcare / Medical\r\n",
        "\r\n",
        "i) **Does a patient has cancer?**\r\n",
        "\r\n",
        "- Let us say we have a dataset of cancer patients to be used in predictive modelling, and based on some inputs, the model will predict whether a patient is diagnosed with cancer or is a healthy patient. The resulting value can be either called a class or target or dependent variables. As this is a classification problem, we will use 'class'. So, for this example, we have two class values as “Cancer” and “Healthy/No Cancer”.\r\n",
        "\r\n",
        "- Let us suppose we have a dataset of 1000 patients, out of which 80 are cancer patients and the rest (920) are healthy. This is an example of an imbalanced dataset, as the majority class is about 9 times bigger than the minority class. Here the majority class is Healthy, and minority class is “Cancer”. Such a dataset is called an Imbalanced Dataset.\r\n",
        "\r\n",
        "ii) **predicting Covid Positive or Covid Negative**\r\n",
        "\r\n",
        "- Suppose that you have to build a classification model on the given Covid-19 data set.You have applied your favourite algorithm and achieved 94% accuracy in predicting Covid Positive or Covid Negative.But still your boss is not happy and threw your model into the trash. You are surprised that model is working fine without any visible defect and with higher accuracy.\r\n",
        "\r\n",
        "- After close analysis you found that Covid19 infection rate is only 6–7% and that is why in given data set Positive class is only 7% and Negative class is around 93%. That is highly Imbalanced data set and my model is behaving in a very interesting way and predicting every case as Negative class and giving accuracy as high as 94% but not predicting any positive class correctly.That is actually a blunder not predicting Covid19 patient as positive while it is.\r\n",
        "\r\n",
        "- **Rare disease**\r\n",
        "\r\n",
        "- Imagine you are a medical professional who is training a classifier to detect whether an individual has an extremely rare disease. You train your classifier, and it yields 99.9% accuracy on your test set. You’re overcome with joy by these results, but when you check the labels outputted by the classifier, you see it always outputted “No Disease,” regardless of the patient data. What’s going on?!\r\n",
        "\r\n",
        "- Because the disease is extremely rare, there were only a handful of patients with the disease in your dataset compared the thousands of patients without the disease. Because over 99.9% of the patients in your dataset don’t have the disease, any classifier can achieve an impressively high accuracy simply by returning “No Disease” to every new patient.\r\n",
        "\r\n",
        "- This is an example of the class imbalance problem where the number of data points belonging to the minority class (in our case, “Disease”) is far smaller than the number of the data points belonging to the majority class (“No Disease”). Besides medical diagnoses, this problem also appears in other domains, such as fraud detection and outlier detection.\r\n",
        "\r\n",
        "## 4. Email\r\n",
        "\r\n",
        "- A typical example of imbalanced data is encountered in e-mail classification problem where emails are classified into ham or spam. The number of spam emails is usually lower than the number of relevant (ham) emails. So, using the original distribution of two classes leads to imbalanced dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvBXQnHYxOP7"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTlA2wSVK-Ub"
      },
      "source": [
        "## 1. Resampling Your Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y0TCjoULDRS"
      },
      "source": [
        "- You can add copies of instances from the under-represented class called over-sampling (or more formally sampling with replacement)\r\n",
        "\r\n",
        "- You can delete instances from the over-represented class, called under-sampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDWcxluYLTQz"
      },
      "source": [
        "### Some Rules of Thumb\r\n",
        "- Consider testing under-sampling when you have an a lot data (tens- or hundreds of thousands of instances or more)\r\n",
        "\r\n",
        "- Consider testing over-sampling when you don’t have a lot of data (tens of thousands of records or less)\r\n",
        "\r\n",
        "- Consider testing random and non-random (e.g. stratified) sampling schemes.\r\n",
        "\r\n",
        "- Consider testing different resampled ratios (e.g. you don’t have to target a 1:1 ratio in a binary classification problem, try other ratios)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqk7eX6iNv_V"
      },
      "source": [
        "## 2. Synthetic Samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYxBUndhODws"
      },
      "source": [
        "- SMOTE or the Synthetic Minority Over-sampling Technique\r\n",
        "\r\n",
        "- As its name suggests, SMOTE is an oversampling method. It works by creating synthetic samples from the minor class instead of creating copies. The algorithm selects two or more similar instances (using a distance measure) and perturbing an instance one attribute at a time by a random amount within the difference to the neighboring instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyKii7cTRXCd"
      },
      "source": [
        "- Decision trees often perform well on imbalanced datasets. The splitting rules that look at the class variable used in the creation of the trees, can force both classes to be addressed.\r\n",
        "\r\n",
        "- If in doubt, try a few popular decision tree algorithms like C4.5, C5.0, CART, and Random Forest."
      ]
    }
  ]
}