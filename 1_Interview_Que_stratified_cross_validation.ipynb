{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_Interview-Que_stratified cross-validation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJ/eqTQAk/xxXZFV2LfyPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sureshmecad/Google-Colab/blob/master/1_Interview_Que_stratified_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6-AEZzyo6tf"
      },
      "source": [
        "## **What is stratified cross-validation and when should we use it?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W261eWLcpBXJ"
      },
      "source": [
        "-----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOFIFTQBpKLK"
      },
      "source": [
        "- Cross-validation is a technique for dividing data between training and validation sets. On typical cross-validation this split is done randomly. But in stratified cross-validation, the split preserves the ratio of the categories on both the training and validation datasets.\n",
        "\n",
        "- For example, if we have a dataset with **10% of category A** and **90% of category B**, and we use stratified cross-validation, we will have the **same proportions** in training and validation. In contrast, if we use **simple cross-validation**, in the **worst case** we may find that there are **no samples of category A in the validation set.**\n",
        "\n",
        "- Stratified cross-validation may be applied in the following scenarios:\n",
        "\n",
        " - On a dataset with **multiple categories**. The **smaller the dataset** and the more **imbalanced the categories**, the more important it will be to use stratified cross-validation.\n",
        "\n",
        " - On a dataset with data of different distributions. For example, in a dataset for **autonomous driving**, we may have **images** taken during the **day and at night**. If we **do not ensure that both types are present** in training and validation, we will have generalization problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASD_FLY3paKr"
      },
      "source": [
        "**************************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82jRKBZdprps"
      },
      "source": [
        "### **What is stratified cross-validation and when should we use it?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-5QVzvgpqSl"
      },
      "source": [
        "- When we are dealing with classification problem of **imbalance class distribution**, we have to use **StratifiedKFold**.\n",
        "\n",
        "- KFold devides the dataset into k folds.\n",
        "\n",
        "- Where as **Stratified** ensures that **each fold** of dataset has the **same proportion** of observations with a given label.\n",
        "\n",
        "- For example, if we have a dataset with **10% of category A and 90% of category B**, and we use stratified cross-validation, we will have the **same proportions in training and validation**. In contrast, if we use simple cross-validation, in the worst case we may find that there are **no samples of category A in the validation set.**\n",
        "\n",
        "- On a dataset with data of different distributions. For example, in a dataset for autonomous driving, we may have images taken during the **day and at night.** If we do not ensure that **both types are present in training and validation**, we will have generalization problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MEH6JmMp1_O"
      },
      "source": [
        "- **Stratified kfold cross validation** is an extension of regular **kfold cross validation** but specifically for **classification** problems where rather than the **splits being completely random**, the ratio between the **target classes** is the same in **each fold** as it is in the full dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcSQejUwp3J-"
      },
      "source": [
        "- In machine learning, When we want to train our ML model we split our entire dataset into **training_set and test_set** using train_test_split() class present in sklearn.Then we train our model on training_set and test our model on test_set. The problems that we are going to face in this method are:\n",
        "\n",
        "- Whenever we **change** the **random_state** parameter present in train_test_split(), We get **different accuracy for different random_state** and hence we can’t exactly point out the accuracy for our model.\n",
        "\n",
        "- The **train_test_split()** splits the dataset into **training_test and test_set** by **random sampling**.But stratified sampling is performed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90ZWTalnqL1A"
      },
      "source": [
        "----------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTHD7Rljp3h2"
      },
      "source": [
        "### **What is random sampling and Stratified sampling?**\n",
        "\n",
        "##### **Random Sampling**\n",
        "\n",
        "- Suppose you want to take a **survey** and decided to call **1000 people from a particular state**, If you pick **either 1000 male completely or 1000 female completely or 900 female and 100 male (randomly)** to ask their opinion on a particular product.\n",
        "\n",
        "- Then based on these 1000 opinion you **can’t decide the opinion** of that **entire state** on your product.\n",
        "\n",
        "##### **Stratified Sampling**\n",
        "\n",
        "- But in Stratified Sampling, Let the population for that state be **51.3% male** and **48.7% female**, Then for choosing 1000 people from that state if you pick **531 male ( 51.3% of 1000 ) and 487 female ( 48.7% for 1000 )** i.e **531 male + 487 female (Total=1000 people)** to ask their opinion. Then these groups of people represent the entire state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duGeEgv-qHrl"
      },
      "source": [
        "--------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g20lVNCzo2UI"
      },
      "source": [
        "### **Why random sampling is not preferred in machine learning?**\n",
        "\n",
        "- Let’s consider a **binary-class classification** problem. Let our dataset consists of **100 samples out of which 80 are negative class { 0 } and 20 are positive class { 1 }.**\n",
        "\n",
        "##### **Random sampling:**\n",
        "\n",
        "- If we do random sampling to split the dataset into training_set and test_set in 8:2 ratio respectively.\n",
        "\n",
        "- Then we might get **all negative class {0} in training_set i.e 80 samples in training_test** and **all 20 positive class {1} in test_set.**\n",
        "\n",
        "- Now if we train our model on training_set and test our model on test_set, Then obviously we will get a **bad accuracy score**.\n",
        "\n",
        "##### **Stratified Sampling:**\n",
        "\n",
        "- The **training_set** consists of **64 negative class{0} ( 80% 0f 80 )** and **16 positive class {1} ( 80% of 20 )** i.e. **64{0}+16{1}=80** samples in training_set which represents the original dataset in **equal proportion**.\n",
        "\n",
        "- Similarly **test_set** consists of **16 negative class {0} ( 20% of 80 ) and 4 positive class{1} ( 20% of 20 )** i.e. **16{0}+4{1}=20** samples in test_set which also represents the **entire dataset in equal proportion**.\n",
        "\n",
        "- This type of **train-test-split** results in **good accuracy**."
      ]
    }
  ]
}