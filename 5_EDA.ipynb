{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_EDA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMoXV7Hvjd8e7oQ3OpQ4IA8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sureshmecad/Google-Colab/blob/master/5_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmOvUuHlqux4"
      },
      "source": [
        "### Objective of EDA\n",
        "- It is basically used to filter the data from redundancies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNZHPc98q0KW"
      },
      "source": [
        "1. Understand the data\n",
        "\n",
        "    a. head()\n",
        "\n",
        "    b. tail()\n",
        "\n",
        "    c. shape\n",
        "\n",
        "    d. info()\n",
        "\n",
        "    e. columns\n",
        "\n",
        "    g. describe\n",
        "\n",
        "       i) if standard deviation is 0 for a particular variable, drop that variable from analysis\n",
        "\n",
        "    h. nunique\n",
        "\n",
        "2. Clean the data\n",
        "\n",
        "    a. check for null values; df.isnull().sum()\n",
        "\n",
        "    b. Remove all unnecessory redudant variables\n",
        "    \n",
        "        i) Drop unimportant variables\n",
        "           df.drop(['race', 'education'], axis=1)\n",
        "\n",
        "       ii) Drop duplicate rows\n",
        "           df.drop_duplicates(keep='first')\n",
        "\n",
        "    c. Replace space in column name\n",
        "\n",
        "        cars.columns.str.replace(' ', '')\n",
        "\n",
        "    b. Outliers\n",
        "\n",
        "3. Analysis of Relationship between variables\n",
        "\n",
        "    a. Heatmap\n",
        "\n",
        "    b. pairplot\n",
        "\n",
        "    c. relplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtHMFfYArpfv"
      },
      "source": [
        "- **EDA** is nothing but a **data exploration** technique to understand the various aspects of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSDSaEYoAxbd"
      },
      "source": [
        "### Exploratory Data Analysis\n",
        "- Exploratory data analysis is an approach to analyzing data sets by summarizing their main characteristics with visualizations.\n",
        "\n",
        "1. Read and examine a dataset and classify variables by their type: **quantitative vs. categorical**\n",
        "\n",
        "2. Handle **categorical variables**\n",
        "\n",
        "3. Perform **univariate and bivariate analysis** and derive meaningful insights about the dataset\n",
        "\n",
        "4. Identify and treat **missing values**\n",
        "\n",
        "5. Remove dataset **outliers**\n",
        "\n",
        "6. Build a **correlation matrix** to identify relevant variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rh0lSJQjM5h"
      },
      "source": [
        "https://www.youtube.com/watch?v=JG8GRlMjp3c\n",
        "\n",
        "https://www.youtube.com/watch?v=IkvwXPEBlNo\n",
        "\n",
        "https://www.youtube.com/watch?v=-o3AxdVcUtQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhEJZIo1d7nZ"
      },
      "source": [
        "## 3. Perform **univariate and bivariate analysis** and derive meaningful insights about the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q10HO5SkIaMe"
      },
      "source": [
        "1. Categorical\n",
        "\n",
        " - Categorical data :\n",
        "\n",
        "     1. Numerical Summaries\n",
        "     2. Histograms\n",
        "     3. Pie Charts\n",
        "\n",
        "2. Univariate Analysis\n",
        "\n",
        "  - **Univariate Analysis** : data consists of only **one variable (only x value).**\n",
        "\n",
        "     1. Line Plots / Bar Charts\n",
        "\n",
        "     2. Histograms\n",
        "\n",
        "     3. Box Plots\n",
        "\n",
        "     4. Count Plots\n",
        "\n",
        "     5. Descriptive Statistics techniques\n",
        "\n",
        "     6. Violin Plot\n",
        "\n",
        "3. Bivariate Analysis\n",
        "\n",
        "  - **Bivariate Analysis** : data involves **two different variables.**\n",
        "\n",
        "     1. Bar Charts\n",
        "\n",
        "     2. Scatter Plots\n",
        "\n",
        "     3. FacetGrid\n",
        "\n",
        "  - There are three types of bivariate analysis\n",
        "\n",
        "     1. Numerical & Numerical\n",
        "\n",
        "     2. Categorical & Categorical\n",
        "\n",
        "     3. Numerical & Categorical\n",
        "\n",
        "\n",
        "4. Multivariate Analysis\n",
        "\n",
        "  - **Multivariate Analysis** : data involves **more than two variables.**\n",
        "\n",
        "    1. Pair Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4OkWQT8MTEn"
      },
      "source": [
        "### Univariate Analysis\n",
        "\n",
        "- **1. Categorical columns**\n",
        "\n",
        "    - For Categorical values we can't do Summary statistics, Histogram & Probability distribution function\n",
        "\n",
        "     i) **Count by category**\n",
        "\n",
        "          cars.groupby('Make').size()\n",
        "     \n",
        "     ii) **Distribution of Categorical variables** by Box and Bar plots\n",
        "\n",
        "          a) Bar plot\n",
        "     \n",
        "        - we use the **value_count() and plot.bar()** functions to draw a **bar plot**, which is commonly used for representing categorical data using rectangular bars with value counts of the categorical values.\n",
        "\n",
        "              sales_data['MarketingType'].value_counts().plot.bar(title='Freq dist of Marketing Type')\n",
        "\n",
        "   - Similarly, by changing the column name in the code above, we can analyze every categorical column.\n",
        "\n",
        "\n",
        "- **2. Numerical columns**\n",
        "\n",
        "    - univariate distribution of the **numerical columns** which contains the histograms.\n",
        "    \n",
        "    i) **Histogram**\n",
        "        \n",
        "           num_bins=10\n",
        "        \n",
        "           plt.hist(cars['length'], num_bins)\n",
        "\n",
        "    ii) Probability distribution function. We use **displot** of the seaborn library to plot this graph\n",
        "\n",
        "           sns.distplot(cars['length'], bins=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4E6Y_cngwqp"
      },
      "source": [
        "## 5. **Outlier** detection analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkYIInBpg4C4"
      },
      "source": [
        "- Outlier might indicate a **mistake in the data (like a typo, or a measuring error, seasonal effects etc)**, in which case it should be **corrected or removed** from the data before calculating **summary statistics or deriving insights from the data**, failing to which will lead to incorrect analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IJUPZfDeh1s"
      },
      "source": [
        "## 6. Build a **correlation matrix** to identify relevant variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaZ5wHEeiTE"
      },
      "source": [
        "- To measure how strong a **relationship is between two variables**. Each attribute of the dataset is compared with the other attributes to find out the correlation coefficient. This analysis allows you to see which pairs have the **highest correlation**, the pairs which are highly correlated represent the same variance of the dataset thus we can further analyze them to understand which attribute among the pairs are most significant for building the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N9G3jRMfM2V"
      },
      "source": [
        "- **Correlation** value lies between **-1 to +1.**\n",
        "\n",
        "- **Highly correlated** variables will have correlation value **close to +1**\n",
        "\n",
        "- **Less correlated** variables will have correlation value **close to -1**\n",
        "\n",
        "- The **diagonal elements** of the matrix value are **always 1** as we are finding the **correlation between the same columns**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCUlzmP4zw92"
      },
      "source": [
        "------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoWA70xHzyx1"
      },
      "source": [
        " if your dataset is too noisy and contains a large portion of null values, then I suggest you first do data cleaning before EDA (probably 0th step) otherwise you can implement data cleaning after EDA and before Baseline model. The pre-processing can be implemented with or before your feature engineering step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wbFPI45AuF6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}